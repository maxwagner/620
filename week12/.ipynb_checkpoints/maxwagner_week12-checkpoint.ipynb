{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Wagner\n",
    "### Data 620 - Week 12 - Project 4 - Q4\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, random, sklearn\n",
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Out Words, Create a Naive Bayes Classifier\n",
    "\n",
    "It should be noted that most of this week's work came straight from the course's reading material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(65)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = all_words.keys()[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Test the Classifier's Accuracy and Print Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy: \" + str(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(doubts) = True              pos : neg    =      9.6 : 1.0\n",
      "          contains(sans) = True              neg : pos    =      8.4 : 1.0\n",
      "    contains(mediocrity) = True              neg : pos    =      7.0 : 1.0\n",
      "     contains(dismissed) = True              pos : neg    =      7.0 : 1.0\n",
      "   contains(bruckheimer) = True              neg : pos    =      6.3 : 1.0\n",
      "     contains(uplifting) = True              pos : neg    =      6.1 : 1.0\n",
      "           contains(ugh) = True              neg : pos    =      5.8 : 1.0\n",
      "     contains(sickening) = True              neg : pos    =      5.7 : 1.0\n",
      "   contains(overwhelmed) = True              pos : neg    =      5.7 : 1.0\n",
      "       contains(topping) = True              pos : neg    =      5.7 : 1.0\n",
      "          contains(wits) = True              pos : neg    =      5.7 : 1.0\n",
      "          contains(lang) = True              pos : neg    =      5.7 : 1.0\n",
      "         contains(wires) = True              neg : pos    =      5.0 : 1.0\n",
      "          contains(caan) = True              neg : pos    =      5.0 : 1.0\n",
      "        contains(fabric) = True              pos : neg    =      5.0 : 1.0\n",
      "  contains(effortlessly) = True              pos : neg    =      5.0 : 1.0\n",
      "         contains(tripe) = True              neg : pos    =      4.6 : 1.0\n",
      "         contains(crowe) = True              pos : neg    =      4.6 : 1.0\n",
      "          contains(hugo) = True              pos : neg    =      4.6 : 1.0\n",
      "       contains(flooded) = True              neg : pos    =      4.3 : 1.0\n",
      "       contains(quicker) = True              neg : pos    =      4.3 : 1.0\n",
      "       contains(maxwell) = True              neg : pos    =      4.3 : 1.0\n",
      "           contains(tv2) = True              neg : pos    =      4.3 : 1.0\n",
      "         contains(locks) = True              neg : pos    =      4.3 : 1.0\n",
      "      contains(matheson) = True              pos : neg    =      4.3 : 1.0\n",
      "          contains(wang) = True              pos : neg    =      4.3 : 1.0\n",
      "        contains(quaint) = True              pos : neg    =      4.2 : 1.0\n",
      "   contains(understands) = True              pos : neg    =      4.1 : 1.0\n",
      "     contains(testament) = True              pos : neg    =      3.9 : 1.0\n",
      "    contains(cronenberg) = True              pos : neg    =      3.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic explanation is that certain words tend to have either a positive or negative connotation in addition to their proper denotation. People are more likely to use words they associate with negativity in a negative review, likewise for positivity. \n",
    "\n",
    "An additional trouble with feature classifiers is that they are heavily dependent on a fairly small subset of training data. If that data contains some very specific words, it could confuse the classifier. For example, the word **maxwell** appeared to occur 4.3:1 in favor of negativity. This could be due to a small number of reviews speaking badly of a character or author. \n",
    "\n",
    "A accuracy of 68% is not great, but it is better than guessing by about 18%. A more comprehensive model with sentence structure included would probably greatly increase the accuracy.\n",
    "\n",
    "#### A few other oddities:\n",
    "- *mediocrity* was surprisingly negative for a word that essentially means neutral\n",
    "- *wires* was also more negative that I expected it to be, possibly due to phrases like, \"the wires were showing\"\n",
    "- *dismissed* was very positive, which I figured could have been used in either catagory\n",
    "- the sheer amount of names in the top 30, made me wonder how effective this method really is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
