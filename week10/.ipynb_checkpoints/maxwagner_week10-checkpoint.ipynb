{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Wagner\n",
    "### Data 620 - Week 10 - Document Classification \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data, and type out nearly 1000 names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "%matplotlib inline\n",
    "\n",
    "spam = pd.read_csv(\"spambase/spambase.data\")\n",
    "spam.columns = ['word_freq_make','word_freq_address','word_freq_all','word_freq_3d','word_freq_our','word_freq_over',\n",
    "                'word_freq_remove','word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive','word_freq_will',\n",
    "                'word_freq_people','word_freq_report','word_freq_addresses','word_freq_free','word_freq_business',\n",
    "                'word_freq_email','word_freq_you','word_freq_credit','word_freq_your','word_freq_font','word_freq_000',\n",
    "                'word_freq_money','word_freq_hp','word_freq_hpl','word_freq_george','word_freq_650','word_freq_lab',\n",
    "                'word_freq_labs','word_freq_telnet','word_freq_857','word_freq_data','word_freq_415','word_freq_85',\n",
    "                'word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm','word_freq_direct',\n",
    "                'word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project','word_freq_re',\n",
    "                'word_freq_edu','word_freq_table','word_freq_conference','char_freq_;','char_freq_(','char_freq_[',\n",
    "                'char_freq_!','char_freq_$','char_freq_#','capital_run_length_average','capital_run_length_longest',\n",
    "                'capital_run_length_total','is_spam'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Split into training and testing, make sure it split okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam: 4600 | train: 3220 | test: 1380\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(spam, test_size = 0.3)\n",
    "print \"spam: \" + str(len(spam)) + \" | train: \" + str(len(train)) + \" | test: \" + str(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Random Forest\n",
    "Let's try this with random forest first, then maybe another method after depending on how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_rf = RandomForestClassifier(n_jobs = -1)\n",
    "spam_rf_fit = spam_rf.fit(train, train['is_spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Spam       1.00      1.00      1.00       838\n",
      "        Ham       1.00      1.00      1.00       542\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_rf_test = spam_rf_fit.predict(test)\n",
    "print metrics.classification_report(test['is_spam'], spam_rf_test, target_names=[\"Spam\", \"Ham\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is saying that random forest is 100% accurate? Seems fishy, let's try it again with a much smaller training group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam: 4600 | train: 46 | test: 4554\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(spam, test_size = 0.99)\n",
    "print \"spam: \" + str(len(spam)) + \" | train: \" + str(len(train)) + \" | test: \" + str(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Spam       0.98      0.99      0.98      2760\n",
      "        Ham       0.98      0.96      0.97      1794\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_rf = RandomForestClassifier(n_jobs = -1)\n",
    "spam_rf_fit = spam_rf.fit(train, train['is_spam'])\n",
    "spam_rf_test = spam_rf_fit.predict(test)\n",
    "print metrics.classification_report(test['is_spam'], spam_rf_test, target_names=[\"Spam\", \"Ham\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with only using 46 instances to train the model with, it is still predicting correctly 90%+ of the time. I'm assuming this is caused by the data set being pretty uniform without a whole lot of variance in types of spam. Applying this model to other corpus' of text would probably not work too well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### SVM\n",
    "\n",
    "I wanted to try another method to see the comparison between the two. This method is using support vector machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam: 4600 | train: 3220 | test: 1380\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(spam, test_size = 0.3)\n",
    "print \"spam: \" + str(len(spam)) + \" | train: \" + str(len(train)) + \" | test: \" + str(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_svm = svm.SVC()\n",
    "spam_svm_fit = spam_svm.fit(train, train['is_spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Spam       0.90      0.85      0.88       845\n",
      "        Ham       0.79      0.84      0.81       535\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_svm_test = spam_svm_fit.predict(test)\n",
    "print metrics.classification_report(test['is_spam'], spam_svm_test, target_names=[\"Spam\", \"Ham\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more in line with what I expected from a classification model. Let's try again with the low training amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam: 4600 | train: 46 | test: 4554\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(spam, test_size = 0.99)\n",
    "print \"spam: \" + str(len(spam)) + \" | train: \" + str(len(train)) + \" | test: \" + str(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_svm = svm.SVC()\n",
    "spam_svm_fit = spam_svm.fit(train, train['is_spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Spam       0.61      0.97      0.75      2760\n",
      "        Ham       0.56      0.06      0.11      1794\n",
      "\n",
      "avg / total       0.59      0.61      0.50      4554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_svm_test = spam_svm_fit.predict(test)\n",
    "print metrics.classification_report(test['is_spam'], spam_svm_test, target_names=[\"Spam\", \"Ham\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse, but still better than guessing and with only 46 training sets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Summary\n",
    "\n",
    "RandomForest outperformed my expectations and the SVM method. Even with low training data it still provided a fairly accurate account of what would be spam or ham."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
